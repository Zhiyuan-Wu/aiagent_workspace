# 课程学习实验计划

## 1. 背景与动机

### 1.1 当前训练策略的局限性

**当前实现**（`models.py`, `data_generator.py`）：
- 所有训练样本随机打乱，均匀参与训练
- 未考虑样本难度差异
- 简单样本和困难样本同等对待

**主要问题**：
1. **早期过拟合**：模型在简单样本上过拟合，难以泛化到困难样本
2. **训练不稳定**：损失震荡，收敛慢
3. **效率低下**：大量时间浪费在已学会的简单样本上
4. **性能次优**：最终模型在困难样本上表现不佳

### 1.2 课程学习优势

**核心思想**：从简单样本开始，逐渐过渡到复杂样本，模拟人类学习过程

**理论依据**：
- **认知模拟**：模仿人类从易到难的学习过程
- **正则化效应**：早期平滑正则化，后期精细拟合
- **收敛加速**：早期快速收敛，后期稳定优化

**预期效果**：
- **训练稳定性提升**：损失曲线更平滑
- **泛化能力提升**：IC标准差降低，ICIR提升
- **最终性能提升**：年化收益提升2-5%

---

## 2. 实验设计原则

### 2.1 固定条件

为避免混淆变量，以下参数在所有实验中保持固定：

- **特征**：使用现有200+因子（不做任何修改）
- **模型**：使用MLP基线模型（hidden=[512,256,128]，避免架构干扰）
- **主损失**：保持pairwise排序的BCE损失
- **排序方法**：自适应边界聚焦（使用最优参数）
- **数据范围**：2017-2020年测试集
- **训练数据**：2008-2014年训练集，2015-2016年验证集
- **随机种子**：固定为42（确保可复现性）

### 2.2 评估标准

- **主要指标**：年化收益率（用于选择最优课程策略）
- **辅助指标**：IC、Rank IC、夏普比率、最大回撤、ICIR

### 2.3 课程学习实现框架

**课程定义维度**：
1. **样本难度**：如何定义"简单"vs"困难"
2. **课程调度**：如何控制难度递进
3. **批次组织**：如何组织训练批次

**修改位置**：
- `data_generator.py`：添加课程学习数据生成器
- `models.py`：训练循环支持课程调度

---

## 3. 实验列表

### 实验 0: Baseline（无课程学习）

**目标**：建立基准性能

**设置描述**：
- 课程策略：无（标准训练）
- 样本组织：随机打乱，所有样本同等概率
- 批次大小：1024（固定）
- 训练轮数：20

**预期性能**（基于历史运行）：
- IC: ~0.030-0.040
- 年化收益率: ~7-9%
- 夏普比率: ~0.85-0.95
- 最大回撤: ~32-38%

---

### 实验 1: 难度定义对比

**目标**：确定最优的样本难度定义

**变量**：样本难度度量方式

**详细配置对比**：

**配置1: 收益率差异（基于标签）**
- 难度计算：abs(return_a - return_b)
- 难度解释：两只股票的未来收益差异
- 简单样本：差异>5%（收益差异大，排序容易）
- 困难样本：差异<1%（收益差异小，排序困难）
- 中等样本：差异在1-5%之间
- 难度分布：简单30%，中等40%，困难30%
- 预期效果：
  - IC提升：+0.002-0.005（更合理的样本权重）
  - 年化收益提升：+1-3%
  - 优势：直观，直接对齐标签
  - 劣势：标签噪声可能影响难度估计

**配置2: 预测置信度（基于模型不确定性）**
- 难度计算：model_uncertainty = std([predictions across multiple models/ensembles])
- 简单样本：不确定性<0.1（模型一致，排序容易）
- 困难样本：不确定性>0.3（模型分歧大，排序困难）
- 中等样本：不确定性在0.1-0.3之间
- 难度分布：简单40%，中等35%，困难25%
- 计算方式：
  - 方法A：使用上一epoch的预测方差
  - 方法B：使用Dropout在多次前向传播下的预测方差
- 预期效果：
  - IC提升：+0.005-0.010（动态难度，适应训练过程）
  - 年化收益提升：+2-4%
  - 优势：自适应，捕捉模型学习动态
  - 劣势：需要ensemble或多次前向传播（计算开销）

**配置3: 特征空间距离**
- 难度计算：feature_distance = ||features_a - features_b||_2
- 简单样本：距离>threshold_75（特征差异大，容易区分）
- 困难样本：距离<threshold_25（特征相似，难以区分）
- 中等样本：距离在threshold_25和threshold_75之间
- 阈度分布：简单35%，中等40%，困难25%
- threshold定义：基于所有训练样本的特征距离分位数
- 预期效果：
  - IC提升：+0.003-0.008（基于特征空间几何）
  - 年化收益提升：+1.5-3.5%
  - 优势：模型无关，预处理阶段计算
  - 劣势：计算成本高（需要所有样本对距离）

**配置4: 排序不确定性**
- 难度计算：基于排序位次的边界模糊性
- 简单样本：top50确定性高（明显优于top51-100）
- 困难样本：rank 40-60之间（边界区域，排序不确定）
- 中等样本：其他
- 难度分布：简单30%，中等40%，困难30%
- 预期效果：
  - IC提升：+0.002-0.006（关注关键边界区域）
  - 年化收益提升：+0.5-2%
  - 优势：直接优化top-k选择
  - 劣势：仅关注排序，未考虑收益

**配置5: 组合难度（多维度）**
- 难度计算：combined = w1×label_difficulty + w2×feature_distance + w3×rank_uncertainty
- 权重选项：
  - 均衡：w=[0.4, 0.3, 0.3]
  - 标签优先：w=[0.5, 0.3, 0.2]
  - 特征优先：w=[0.3, 0.5, 0.2]
- 难度标准化：归一化到[0,1]
- 预期效果：
  - IC提升：+0.006-0.012（综合利用多维度信息）
  - 年化收益提升：+2-4%（最优单维度）
  - 优势：全面性，鲁棒性强
  - 劣势：权重需要调优

**关键假设**：
- 预测置信度（配置2）最有效（动态适应）
- 组合难度（配置5）最鲁棒（信息全面）
- 收益率差异（配置1）最直观但受噪声影响

**评估方法**：
- 对比各难度定义的年化收益率
- 对比IC标准差（稳定性）
- 分析难度分布直方图

---

### 实验 2: 课程调度策略

**目标**：确定最优的难度递进调度策略

**变量**：难度递进方式

**详细配置对比**：

**配置1: 阶梯式调度**
- 难度策略：epoch 0-5只训练简单样本，epoch 6-10训练简单+中等，epoch 11-15训练简单+中等+困难，epoch 16-20训练所有样本
- 难度阈值：
  - Epoch 0-5: 只用简单（难度<0.3）
  - Epoch 6-10: 简单+中等（难度<0.6）
  - Epoch 11-15: 简单+中等+困难（难度<0.9）
  - Epoch 16-20: 所有样本（难度<1.0）
- 优点：平滑过渡，稳定训练
- 缺点：过于保守，后期才用困难样本
- 预期效果：
  - IC提升：+0.004-0.008（避免早期困难样本干扰）
  - 年化收益提升：+2-4%
  - 训练稳定性：损失曲线更平滑

**配置2: 线性调度**
- 难度策略：每个epoch增加可用困难样本的比例
  - 比例：
  - Epoch 1: 10%困难，90%简单
  - Epoch 5: 30%困难，70%简单
  - Epoch 10: 50%困难，50%简单
  - Epoch 15: 70%困难，30%简单
  - Epoch 20: 90%困难，10%简单
- 难度阈值：动态计算（当前epoch的难度分位数）
- 优点：渐进过渡，充分学习
- 缺点：每个epoch仍包含简单样本
- 预期效果：
  - IC提升：+0.006-0.010（更好的渐进学习）
  - 年化收益提升：+3-5%（最优）
  - 训练速度：略快于阶梯式

**配置3: 指数调度**
- 难度策略：difficulty_ratio = (epoch / total_epochs)^p
- p参数（幂次）：
  - p=1: 线性增加（与配置2等价）
  - p=2: 凹增加（前期增加快，后期慢）
  - p=3: 对数增加（早期线性，后期平缓）
  - p=0.5: 平缓增加（始终温和）
- 难度阈值：动态计算
- 优点：灵活控制递进速度
- 缺点：p参数需要调优
- 预期效果：
  - p=2最优：IC提升+0.007-0.011
  - 年化收益提升：+3-6%

**配置4:平滑调度（Smooth Curriculum）**
- 难度策略：使用sigmoid函数平滑过渡
- 公式：difficulty_ratio = 1 / (1 + exp(-k × (1 - 2×epoch/total_epochs)))
- k参数（陡峭度）：
  - k=5: 陡峭（快速过渡）
  - k=10: 中等
  - k=20: 平缓（缓慢过渡）
- 优点：非常平滑的训练
- 缺点：后期困难样本增长慢
- 预期效果：
  - k=10最优：IC提升+0.005-0.009
  - 年化收益提升：+2.5-4.5%

**配置5: 混合调度（Annealed Curriculum）**
- 难度策略：结合线性调度和退火
- 阶段1（Epoch 0-10）：线性增加困难样本
- 阶段2（Epoch 11-20）：保持困难样本比例，但降低学习率
- 学习率调整：
  - Epoch 0-10: lr=0.001
  - Epoch 11-15: lr=0.0005
  - Epoch 16-20: lr=0.0002
- 优点：充分利用困难样本，后期精细调优
- 缺点：复杂度高
- 预期效果：
  - IC提升：+0.008-0.012
  - 年化收益提升：+4-6%

**配置6: 自适应调度（Self-paced Learning）**
- 难度策略：根据模型当前性能动态调整
- 性能指标：验证集损失或IC
- 调整策略：
  - 性能提升快：增加困难样本比例
  - 性能停滞：降低难度或保持
  - 性能下降：减少困难样本，回到简单样本
- 频率更新：每5个epoch评估一次
- 阈度比例范围：10%-90%
- 优点：完全自适应，避免过拟合
- 缺点：实现复杂
- 预期效果：
  - IC提升：+0.007-0.011
  - 年化收益提升：+3-5%

**关键假设**：
- 平滑或指数调度优于阶梯调度
- 自适应调度理论上最优但实现复杂
- 后期学习率衰减有帮助

**评估方法**：
- 对比各调度策略的年化收益率
- 绘制训练曲线（损失vs epoch）
- 分析收敛速度（达到目标loss的epoch数）

---

### 实验 3: 批次组织策略

**目标**：确定最优的批次组织方式（课程组织）

**变量**：样本选择策略

**详细配置对比**：

**配置1: 完全随机（Baseline）**
- 批次组织：完全随机抽取样本
- 批次大小：1024
- 难度过滤：无
- 优点：实现简单，无偏
- 缺点：未利用课程信息
- 预期效果：
  - 基准性能

**配置2: 困难样本过滤**
- 批次组织：按难度阈值过滤样本
- 过滤策略：
  - Epoch 0-5: 只用简单样本（难度<0.3）
  - Epoch 6-10: 简单+中等（难度<0.6）
  - Epoch 11-15: 所有样本
  - 难度阈值：参考实验1的最优难度定义
- 优点：实现简单，效果明显
- 缺点：某些epoch可能样本不足
- 预期效果：
  - IC提升：+0.003-0.007
  - 年化收益提升：+2-3%

**配置3: 困难样本过采样**
- 批次组织：保持难度分布平衡
- 过采样策略：
  - Epoch 0-10: 简单:中等:困难 = 5:3:2
  - Epoch 11-20: 简单:中等:困难 = 3:4:3
  - 批次大小：1024（实际可能更小以保持比例）
- 优点：难度多样性，避免样本不足
- 缺点：简单样本可能过拟合
- 预期效果：
  - IC提升：+0.004-0.008
  - 年化收益提升：+2.5-4%

**配置4: 难机样本丢弃（Random Dropping）**
- 批次组织：以概率p丢弃困难样本
- 丢弃概率：
  - Epoch 0-10: p=0.2（简单样本:p=0）
  - Epoch 11-15: p=0.1（简单样本:p=0）
  - Epoch 16-20: p=0.05（简单样本:p=0）
- 优点：早期保护模型，后期充分利用
- 缺点：浪费数据
- 预期效果：
  - IC提升：+0.005-0.009
  - 年化收益提升：+3-5%

**配置5: 重要性加权**
- 批次组织：按难度权重加权损失
- 权重公式：weight = difficulty^alpha
- alpha参数：
  - alpha=1: 线性加权
  - alpha=2: 平方加权（更重视困难样本）
  - alpha=0.5: 根号加权（温和）
- 损失函数：L = weight × BCE_loss
- 优点：灵活控制
- 缺点：超参需要调优
- 预期效果：
  - alpha=2最优：IC提升+0.006-0.010
  - 年化收益提升：+3-5%

**配置6: 混合批次组织（Mixed Batching）**
- 批次组织：每个batch包含所有难度级别
- 比例：256简单+512中等+256困难
- 策略：
  - Epoch 0-10: 困难样本数量少
  - Epoch 11-20: 困难样本数量多
- 优点：梯度稳定，充分利用所有样本
- 缺点：实现复杂
- 预期效果：
  - IC提升：+0.007-0.011
  - 年化收益提升：+4-6%

**关键假设**：
- 批次组织比难度定义更重要
- 加权或过采样优于简单过滤
- 混合策略通常优于单一策略

**评估方法**：
- 对比各组织策略的年化收益率
- 分析训练曲线平滑度
- 对比收敛速度

---

### 实验 4: 初始难度阈值

**目标**：确定最优的初始难度起点

**变量**：第一个epoch的样本难度范围

**详细配置对比**：

**配置1: 从最简单开始**
- 初始难度范围：[0, 0.2]（最简单的20%样本）
- 难度递增：每个epoch增加0.05
- 最终难度范围：[0, 1.0]（所有样本）
- 递增速度：20 epochs / (1.0 - 0.2) = 20/0.8 ≈ 25个epochs
- 优点：模型早期建立稳定表示
- 缺点：前期只用极少样本，收敛慢
- 预期效果：
  - IC提升：+0.003-0.006
  - 年化收益提升：+1-2%
  - 训练稳定性：最高

**配置2: 从简单开始**
- 初始难度范围：[0, 0.4]（较简单的40%样本）
- 难度递增：每个epoch增加0.04
- 递增速度：20 epochs / (1.0 - 0.4) ≈ 17个epochs
- 优点：平衡样本利用
- 预期效果：
  - IC提升：+0.005-0.008（最优）
  - 年化收益提升：+2-4%

**配置3: 从中等开始**
- 初始难度范围：[0, 0.6]（较简单的60%样本）
- 难度递增：每个epoch增加0.03
- 递增速度：20 epochs / (1.0 - 0.6) ≈ 14个epochs
- 优点：快速进入有效训练
- 预期效果：
  - IC提升：+0.004-0.007
  - 年化收益提升：+1.5-3%
  - 训练速度：最快

**配置4: 从简单开始-指数衰减**
- 初始难度范围：[0, 0.4]
- 难度递增：指数衰减，后期增速慢
- 公式：difficulty = 0.4 + 0.6 × (1 - 0.95^epoch)
- 优点：早期快速学习，后期精细调优
- 预期效果：
  - IC提升：+0.006-0.010（可能最优）
  - 年化收益提升：+3-5%

**配置5: 固定比例（Fixed Proportion）**
- 初始策略：每个epoch使用固定难度分布
- 难度比例：简单30%，中等40%，困难30%
- 批次大小：1024
- 优点：稳定训练
- 缺点：未利用递进优势
- 预期效果：
  - IC提升：+0.002-0.004
  - 年化收益提升：+1-2%

**关键假设**：
- 从简单开始但有足够样本优于极端保守
- 指数衰减优于线性递增
- 初始难度在0.4-0.6之间最优

**评估方法**：
- 对比各初始难度的学习曲线
- 分析初始阶段的收敛速度
- 对比最终性能

---

### 实验 5: 预热阶段（Warmup Phase）

**目标**：确定最优的预热策略

**变量**：预热阶段的持续时间和策略

**详细配置对比**：

**配置1: 无预热（Baseline）**
- 预热策略：直接使用完整难度
- 预热长度：0 epochs
- 优点：简单
- 预期效果：
  - 基准性能

**配置2: 短预热（5 epochs）**
- 预热策略：前5个epoch只用简单样本
- 预热难度范围：[0, 0.3]
- 主训练阶段：完整难度
- 优点：模型早期稳定
- 预期效果：
  - IC提升：+0.002-0.005
  - 年化收益提升：+1-2%

**配置3: 中预热（10 epochs）**
- 预热策略：前10个epoch只用简单+中等样本
- 预热难度范围：[0, 0.6]
- 主训练阶段：完整难度
- 优点：充分的早期稳定
- 预期效果：
  - IC提升：+0.004-0.007
  - 年化收益提升：+2-3%

**配置4: 长预热（15 epochs）**
- 预热策略：前15个epoch渐进增加难度
- 难度范围：[0, 0.3] → [0, 0.5] → [0, 0.7]
- 主训练阶段：完整难度
- 优点：非常平滑过渡
- 预期效果：
  - IC提升：+0.005-0.008
  - 年化收益提升：+2.5-3.5%
  - 训练稳定性：最高

**配置5: 自适应预热（Self-paced Warmup）**
- 预热策略：根据验证集性能动态结束预热
- 结束条件：验证集IC连续3个epoch不再提升
- 最小预热：5 epochs
- 最大预热：20 epochs
- 优点：数据驱动，避免过短或过长
- 预期效果：
  - IC提升：+0.006-0.009（可能最优）
  - 年化收益提升：+3-4%

**配置6: 渐进预热（Gradual Warmup）**
- 预热策略：难度和样本量同时渐进
- Epoch 1-5: 10%困难样本，batch_size=512
- Epoch 6-10: 30%困难样本，batch_size=768
- Epoch 11-15: 60%困难样本，batch_size=1024
- Epoch 16-20: 90%困难样本，batch_size=1024
- 优点：充分利用数据
- 预期效果：
  - IC提升：+0.007-0.011
  - 年化收益提升：+4-5%

**关键假设**：
- 预热阶段有助于稳定训练
- 自适应预热优于固定长度
- 渐进预热（同时增加难度和样本量）最优

**评估方法**：
- 对比各预热策略的年化收益率
- 绘制训练曲线前15个epoch
- 分析预热结束时机合理性

---

### 实验 6: 混合课程策略（最优组合）

**目标**：结合前面实验的最优组件

**变量**：课程学习各维度的最优组合

**详细配置对比**：

**配置1: 保守组合（稳定性优先）**
- 难度定义：配置2（预测置信度）
- 课程调度：配置2（线性调度）
- 批次组织：配置3（困难样本过滤）
- 初始难度：配置2（从简单开始）
- 预热阶段：配置4（长预热15 epochs）
- 组合理念：最大化稳定性
- 预期效果：
  - IC提升：+0.008-0.011
  - 年化收益提升：+3-4%
  - IC标准差降低：20-25%
  - 适用场景：风险厌恶

**配置2: 平衡组合（推荐起点）**
- 难度定义：配置2（预测置信度）
- 课程调度：配置2（线性调度）
- 批次组织：配置6（混合批次组织）
- 初始难度：配置3（从简单开始）
- 预热阶段：配置4（长预热15 epochs）
- 组合理念：平衡稳定性和性能
- 预期效果：
  - IC提升：+0.009-0.013
  - 年化收益提升：+4-5%
  - 适用场景：一般情况

**配置3: 激进组合（性能优先）**
- 难度定义：配置5（组合难度）
- 课程调度：配置5（混合调度）
- 批次组织：配置6（混合批次组织）
- 初始难度：配置4（指数衰减）
- 预热阶段：配置6（渐进预热）
- 组合理念：最大化性能
- 预期效果：
  - IC提升：+0.010-0.015（可能最优）
  - 年化收益提升：+5-7%
  - IC标准差降低：10-15%
  - 适用场景：数据充足

**配置4: 自适应组合**
- 难度定义：配置2（动态）
- 课程调度：配置6（自适应调度）
- 批次组织：配置4（随机丢弃）
- 初始难度：配置4（指数衰减）
- 预热阶段：配置5（自适应预热）
- 组合理念：完全自适应
- 预期效果：
  - IC提升：+0.008-0.012
  - 年化收益提升：+4-6%
  - 优点：无需手动调参
  - 缺点：实现复杂

**配置5: 两阶段课程（Two-stage Curriculum）**
- 阶段1（Epoch 0-10）：特征预训练
  - 预热任务：autoencoder（特征重建）
  - 主任务：pairwise排序
  - 损失：0.7×recon_loss + 0.3×ranking_loss
- 阶段2（Epoch 11-20）：排序微调
  - 主任务：pairwise排序
  - 课程学习：配置2（线性调度）
- 组合理念：先学特征表示，再学排序
- 预期效果：
  - IC提升：+0.009-0.013
  - 年化收益提升：+5-8%
  - 适用场景：特征质量高

**配置6: 自适应难度阈值**
- 难度定义：配置2（预测置信度）
- 课程调度：配置6（自适应调度）
- 批次组织：配置5（重要性加权，alpha=2）
- 初始难度：动态调整（基于验证集性能）
- 预热阶段：配置5（自适应预热）
- 难度阈值范围：0.2-0.8之间动态调整
- 组合理念：完全数据驱动
- 预期效果：
  - IC提升：+0.010-0.016（可能最优）
  - 年化收益提升：+5-9%
  - 优点：最鲁棒
  - 缺点：实现最复杂

**关键假设**：
- 组合策略优于单一维度优化
- 保守组合稳定性最好，激进组合性能最优
- 完全自适应策略理论上最优

**评估方法**：
- 对比各组合策略的年化收益率
- 分析稳定性（IC标准差）
- 分析实现复杂度vs性能提升性价比

---

## 4. 实验执行与评估流程

### 4.1 执行顺序

```
实验0（Baseline训练）
    ↓
实验1（难度定义）→ 确定最优难度定义
    ↓
实验2（课程调度）→ 确定最优调度策略
    ↓
实验3（批次组织）→ 确定最优批次组织
    ↓
实验4（初始难度）→ 确定最优初始难度
    ↓
实验5（预热阶段）→ 确定最优预热策略
    ↓
实验6（组合策略）→ 综合最优组件
    ↓
性能对比与最优配置推荐
```

### 4.2 结果记录

每个实验需要记录以下指标：

**训练指标**：
- 最终训练损失
- 收敛速度（达到目标loss的epoch数）
- 训练稳定性（loss标准差）

**预测指标**：
- IC, Rank IC, ICIR
- 年化收益率、夏普比率、最大回撤、Calmar比率

**课程学习指标**：
- 难度分布变化曲线
- 样本利用率（实际使用样本数/总样本数）
- 有效训练样本比例

**结果存储路径**：
```
data/experiments/curriculum_learning/
├── exp00_baseline/
│   ├── config.json
│   ├── results.csv
│   └── plots/
├── exp01_difficulty_definition/
├── exp02_curriculum_schedule/
├── ...
└── exp06_combined_strategy/
```

### 4.3 可视化分析

**关键可视化**：

1. **训练曲线对比**
   - 损失vs epoch（Baseline vs 课程学习）
   - 验证集IC vs epoch
   - 不同策略的收敛速度对比

2. **难度分布分析**
   - 难度分布直方图（不同epoch）
   - 难度递进曲线
   - 样本利用率曲线

3. **性能对比**
   - 各策略性能对比（柱状图）
   - IC标准差对比（稳定性）
   - 年化收益率对比

4. **课程效果分析**
   - 简单样本性能 vs 困难样本性能
   - 早期vs后期样本性能
   - Top-K股票中简单/困难样本比例

---

## 5. 预期贡献

### 5.1 性能提升预期

基于课程学习理论，预期达到以下效果：

| 改进方向 | IC提升 | 年化收益提升 | 夏普比率提升 | 最大回撤降低 |
|---------|---------|--------------|-----------|-------------|
| 难度定义优化 | +0.005-0.010 | +2-4% | +0.05-0.15 | -3-7% |
| 课程调度优化 | +0.005-0.012 | +3-6% | +0.08-0.20 | -5-10% |
| 批次组织优化 | +0.003-0.008 | +2-4% | +0.05-0.12 | -3-6% |
| 预热策略优化 | +0.004-0.009 | +2-4% | +0.07-0.18 | -4-8% |
| **组合策略** | **+0.010-0.020** | **+5-9%** | **+0.10-0.25** | **-8-12%** |

**综合最优配置预期**（组合多个改进）：
- IC提升：从~0.030 → ~0.040-0.050
- 年化收益提升：从~7-9% → ~13-18%
- 夏普比率提升：从~0.85-0.95 → ~1.05-1.20
- 最大回撤降低：从~32-38% → ~24-30%

### 5.2 学术贡献

- **系统性研究**：课程学习在pairwise排序量化投资中的首次系统性应用
- **实证分析**：基于A股数据的课程学习效果量化分析
- **设计原则**：为量化投资中的课程学习设计提供实践指导

### 5.3 实践贡献

- **最优配置推荐**：基于实证数据的最优课程学习配置
- **性能提升**：可操作的5-9%年化收益提升
- **稳定性提升**：ICIR提升15-30%，增强策略可靠性

---

## 6. 时间估算

| 实验编号 | 实验名称 | 配置数量 | 预计耗时（小时） |
|---------|---------|---------|----------------|
| 0 | Baseline | 1 | 2-3 |
| 1 | 难度定义 | 5 | 8-12 |
| 2 | 课程调度 | 6 | 10-15 |
| 3 | 批次组织 | 6 | 10-15 |
| 4 | 初始难度 | 5 | 8-12 |
| 5 | 预热阶段 | 6 | 10-15 |
| 6 | 组合策略 | 6 | 12-18 |
| **总计** | | | **60-90 小时** |

**建议执行周期**：1.5-2周（每周30-45小时计算时间）

---

## 7. 风险与缓解

### 7.1 技术风险

| 风险 | 影响 | 缓解措施 |
|-----|------|---------|
| 难度定义不准确 | 课程效果不明显 | 使用多种难度定义交叉验证 |
| 过拟合训练集 | 测试集性能差 | 时间序列交叉验证，正则化增强 |
| 计算资源需求大 | 训练时间长 | 优先实现高效的难度定义（如配置2） |

### 7.2 业务风险

| 风险 | 影响 | 缓解措施 |
|-----|------|---------|
| 课程策略失效 | 回测表现差 | 保守组合优先，确保稳定性 |
| 收益率不达标 | 收益率低于预期 | 课程学习作为辅助，不影响主任务 |

---

## 8. 成功标准

**实验计划成功的标志**：
1. ✓ 找到相对于Baseline有显著提升（年化收益 > 2%）的最优课程学习配置
2. ✓ 理解不同课程学习组件对性能的影响规律
3. ✓ 完成可复现的课程学习框架
4. ✓ 完成实验报告与可视化分析
5. ✓ 提供明确的课程学习配置推荐
