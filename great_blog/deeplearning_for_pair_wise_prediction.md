### 深度学习因子模型优化实验方案（补充与优化版）

#### 1. 背景
当前 `myportfolio.py` 实现了一个基础的多层感知机（MLP）模型，用于根据输入特征（alpha因子）预测股票收益排序并构建投资组合。该实现较为简单，缺乏现代深度学习中提升性能与稳定性的关键技术。为系统性地探索在A股市场上表现更优的深度学习架构，制定本实验计划。采用**贪心搜索策略**：每个新实验均基于迄今为止回测年化收益率最高的配置，并仅改变一个维度的设置，以清晰评估该修改对投资绩效的影响。

#### 2. 基线模型 (Baseline)
- **网络结构**: 2个隐藏层，每层64个神经元
- **激活函数**: ReLU
- **归一化**: 无
- **正则化**: 无显式正则化（L2权重衰减设为0）
- **损失函数**: **Pairwise Ranking Loss**。模型接收一对股票的特征向量，输出各自得分，通过二元交叉熵或类似分类损失鼓励高收益股票得分更高。
- **优化器**: Adam，初始学习率 1e-4
- **训练设置**: Batch size = 512，训练轮次 = 20
- **其他**: 无残差连接、无辅助损失、无特征预处理

---

#### 3. 实验列表

**实验 0: 测试不同锦标赛方法的效果**
- **目标**: 评估随机配对、单淘汰赛、双败淘汰赛、混合方法、自适应方法进行排序的相对效果。
- **变量**: 固定使用LGBM模型完成这个实验，避免DL模型的干扰，结果可以作为DL模型的参考。
- **先完成这个实验再进行其它DL实验。**

**实验 1: 输入特征工程与预处理**
- **目标**: 原始因子常包含极端值和量纲差异，此实验旨在寻找最佳的数据预处理方式。
- **变量**: 特征处理方法。
- **设置**:
    - **对照组**: Baseline（原始特征）
    - **实验组 A (标准化)**: 对整个训练集进行Z-Score标准化，并用训练集的均值和标准差处理验证/测试集。
    - **实验组 B (缩尾处理 + 标准化)**: 先对特征进行缩尾处理（如上下1%分位数），再进行标准化。
- **预期**: 分位数变换或缩尾处理能有效抑制异常值影响，更适应A股因子中常见的极端情况。

**实验 2: 网络架构&网络深度与宽度探索**
- **目标**: 探索模型容量对性能的影响，确定合适的规模。
- **变量**: 隐藏层数量与每层神经元数。
- **设置**（基于实验1的最佳结果）:
    - **对照组**: 当前最佳配置（如2层×64）
    - **实验组 A（深度）**: [3, 4, 6] 层 × 64 单元
    - **实验组 B（宽度）**: 3 层 × [128, 256, 512] 单元
    - **实验组 C（瓶颈结构）**: 3层结构，维度逐渐递减（如 256 -> 128 -> 64），模拟信息压缩。
    - **实验组 D（纺锤结构）**: 3层结构，维度逐渐增加（如 256 -> 512 -> 256）。
    - **实验组 E（双塔结构）**: 使用共享的encoder分别处理两个输入特征。

- **预期**: 适当增加深度和宽度能提升模型表达能力，但过深可能导致过拟合。瓶颈结构可能有助于提取核心因子。

**实验 3: 现代归一化与残差连接**
- **目标**: 解决深度网络训练不稳定和梯度退化问题。
- **变量**: 归一化方法与残差连接。
- **设置**（基于实验2的最佳结果，使用一个中等深度网络如4层）:
    - **对照组**: 无归一化，无残差连接的标准网络。
    - **实验组 A (BN)**: 在每个隐藏层后、激活函数前添加 `BatchNorm1d`。
    - **实验组 B (LN)**: 在每个隐藏层后、激活函数前添加 `LayerNorm`。
    - **实验组 C (残差连接)**: 将网络重构为残差块形式（如每2层一个残差块），维度变化处使用线性投影。
    - **实验组 D (残差 + LayerNorm)**: 结合实验组B和C。
- **预期**: `LayerNorm` 在时间序列和小批量场景下通常比 `BatchNorm` 更稳定。残差连接能有效支持更深网络，二者结合可能效果最佳。

**实验 4: 激活函数的选择**
- **目标**: ReLU可能存在神经元死亡问题，探索更平滑的激活函数。
- **变量**: 激活函数类型。
- **设置**（基于实验3的最佳结果）:
    - **对照组**: ReLU
    - **实验组 A**: Leaky ReLU / PReLU (Parametric ReLU)
    - **实验组 B**: Swish / SiLU (Sigmoid Linear Unit)
- **预期**: Leaky ReLU 和 ELU 可以缓解梯度消失，Swish 在深层网络上表现优异，可能带来更平滑的优化曲面。

**实验 5: 辅助损失函数 (多任务学习)**
- **目标**: 通过多任务学习引入归纳偏置，让模型学习到更具经济含义的表征。
- **变量**: 辅助任务类型。
- **设置**（基于实验4的最佳结果）:
    - **对照组**: 仅主任务（Pairwise Ranking Loss）
    - **实验组 A (收益预测)**: 总损失 = 主损失 + λ₁ × MSE(预测收益, 未来N日收益)
    - **实验组 B (特征重建)**: 在主损失的基础上，增加一个损失项，鼓励模型重建被随机mask掉的输入特征，来学习高效的表征
    - **超参**: λ₁, λ₂ ∈ {0.1, 0.5, 1.0}。

**实验 6: 优化器、学习率调度与正则化**
- **目标**: 综合提升收敛质量与样本外泛化能力。
- **变量**: 优化器策略、学习率调度与显式正则化。
- **设置**（基于实验5的最佳结果）:
    - **对照组**: Adam (lr=1e-3)，固定学习率，无Dropout，固定50轮。
    - **实验组 A (调度)**: Adam + CosineAnnealingLR 或 `ReduceLROnPlateau`。
    - **实验组 B (优化器)**: AdamW (解耦权重衰减) 或 RAdam (带整流项的Adam)，并尝试 `weight_decay`∈{1e-5, 1e-4, 1e-3}。
    - **实验组 C (Dropout)**: 在隐藏层后添加 Dropout (p ∈ {0.1, 0.2, 0.5})。
    - **实验组 D (早停)**: 引入 Early Stopping（耐心值=10，监控验证集主损失），并与最佳实验组结合。
- **预期**: AdamW 能更有效地进行权重衰减。CosineAnnealing 有助于跳出局部最优。早停是防止过拟合最有效的手段之一。

**实验 7: 数据增广 (Data Augmentation)**
- **目标**: 金融数据有限，增广是提升泛化性的有力手段。
- **变量**: 数据增广方法。
- **设置**（基于实验6的最佳结果）:
    - **对照组**: 无增广。
    - **实验组 A (Cross-sectional Mixup)**: 在同一时间截面上，混合两只不同股票的样本，创造虚拟样本。
    - **实验组 B (特征噪声)**: 向输入特征添加微小的高斯噪声 (N(0, ε))，作为一种隐式正则化。
- **预期**: Mixup 方法能创造出位于训练样本之间的新样本，平滑决策边界，显著提升泛化能力。需要谨慎设计，确保混合后的样本在金融逻辑上依然合理。

**实验 8: 特征交叉与自注意力**
- **目标**: 因子之间可能存在复杂的非线性交互作用，MLP需要深层网络才能隐式捕捉。此实验引入显式的特征交叉机制。
- **变量**: 模型架构。
- **设置**（基于实验7的最佳结果）:
    - **对照组**: 标准MLP。
    - **实验组 A (FM/DeepFM)**: 引入因子分解机层，显式地对所有特征的二阶交互进行建模，再输入DNN。
    - **实验组 B (Self-Attention)**: 将特征视为一个序列（或集合），使用Transformer的Encoder层来捕捉特征之间的相互依赖关系。可以使用 [CLS] token 的输出作为最终的股票得分。
- **预期**: 自注意力机制能够动态地加权不同特征的重要性，并建模特征间的复杂关系，可能比MLP更能捕捉A股市场中的非线性规律。

**实验 9: 实验报告**
- **目标**: 根据所有已有实验结果，形成一份最优配置推荐，测定这种最优配置的性能，最终形成一份完整的实验报告。

#### 4. 实验执行与评估流程
1.  **顺序依赖**: 每个实验严格基于前序实验中年化收益率最高的配置进行。
2.  **可复现性**: 所有实验使用相同随机种子（包括数据划分、模型初始化、PyTorch/Numpy随机种子），确保结果一致。
3.  **回测一致性**: 所有模型在完全相同的回测框架下评估，包括数据范围（如2015-2023年，其中前几年训练，后几年验证/测试）、交易成本（双边千分之二）、行业中性化逻辑及组合构建规则（如选择得分最高的前50只股票，等权或市值加权）。
4.  **多维评估**: 以**年化收益率**为主要选择标准，同时记录夏普比率、最大回撤、Calmar比率、信息比率、月度胜率等指标，用于综合判断，避免单一指标过拟合。
6.  **失败回退**: 若某实验所有变体均劣于其对照组，则保留原配置，继续后续实验。
