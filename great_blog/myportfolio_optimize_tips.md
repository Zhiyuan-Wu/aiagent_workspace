# Pairwise Ranking Strategy - å†…å­˜ä¸æ—¶é—´æ•ˆç‡ä¼˜åŒ–è¦ç‚¹æ€»ç»“

## ä¸€ã€å†…å­˜æ•ˆç‡ä¼˜åŒ–ï¼ˆæ ¸å¿ƒé—®é¢˜ï¼š152ä¸‡é…å¯¹ Ã— 468ç»´ = 7.3GBï¼‰

### 1.1 âœ… **æµå¼æ•°æ®å¤„ç†æ¶æ„**ï¼ˆæœ€é‡è¦ï¼‰
**é—®é¢˜**ï¼šä¸€æ¬¡æ€§ç”Ÿæˆå…¨éƒ¨é…å¯¹ç‰¹å¾çŸ©é˜µ
**è§£å†³**ï¼šæ”¹ä¸ºè¿­ä»£å™¨æ¨¡å¼ï¼Œåˆ†æ‰¹ç”Ÿæˆã€åˆ†æ‰¹è®­ç»ƒ

```python
# âŒ é”™è¯¯ï¼šå…¨é‡åŠ è½½
pair_features = np.array(pair_features_list)  # 7.3GB

# âœ… æ­£ç¡®ï¼šæµå¼å¤„ç†
for batch_features, batch_labels in generator.generate_pairs_batch_iterator():
    X_batch = torch.FloatTensor(batch_features)  # æ¯æ¬¡ä»…~10MB
    train_on_batch(X_batch, batch_labels)
```

### 1.2 âœ… **æ•°æ®ç±»å‹å‹ç¼©**
**é—®é¢˜**ï¼šé»˜è®¤ä½¿ç”¨float64ï¼ˆ8å­—èŠ‚ï¼‰
**è§£å†³**ï¼šé™çº§ä¸ºfloat32ï¼ˆ4å­—èŠ‚ï¼‰ï¼Œå†…å­˜å‡åŠ

```python
# âŒ é”™è¯¯
feat_a = date_features.loc[...].values  # float64

# âœ… æ­£ç¡®
feat_a = date_features.loc[...].values.astype(np.float32)  # 4å­—èŠ‚
batch_labels = np.array(batch_labels, dtype=np.float32)    # 4å­—èŠ‚
```

### 1.3 âœ… **åŠæ—¶å†…å­˜é‡Šæ”¾**
**é—®é¢˜**ï¼šPyTorchå¼ é‡é©»ç•™æ˜¾å­˜/å†…å­˜
**è§£å†³**ï¼šæ˜¾å¼åˆ é™¤å¹¶è§¦å‘GC

```python
# âœ… æ¯ä¸ªbatchåæ¸…ç†
del X_batch, y_batch, pred
if self.device.type == 'cuda':
    torch.cuda.empty_cache()
gc.collect()  # å¯é€‰
```

### 1.4 âœ… **éªŒè¯é›†é‡‡æ ·è¯„ä¼°**
**é—®é¢˜**ï¼šéªŒè¯é›†ä¹Ÿç”Ÿæˆ43ä¸‡é…å¯¹ï¼ˆ1.6GBï¼‰
**è§£å†³**ï¼šåªå–ä¸€ä¸ªbatchè¿›è¡ŒéªŒè¯

```python
# âœ… éªŒè¯é›†åªå–ä¸€æ‰¹
valid_iterator = generator.generate_pairs_batch_iterator(
    valid_features, valid_labels,
    yield_single_batch=True  # å…³é”®ï¼šç”Ÿæˆä¸€æ‰¹ååœæ­¢
)
```

## äºŒã€æ—¶é—´æ•ˆç‡ä¼˜åŒ–

### 2.1 ğŸš€ **å‘é‡åŒ–é…å¯¹é€‰æ‹©**
**é—®é¢˜**ï¼šåŒé‡å¾ªç¯é€è‚¡ç¥¨é…å¯¹ï¼ŒO(nÂ²)å¤æ‚åº¦
**è§£å†³**ï¼šä½¿ç”¨numpyå‘é‡åŒ–æ“ä½œ

```python
# âŒ é”™è¯¯ï¼šO(nÂ²)å¾ªç¯
for inst_a in valid_instruments:
    for inst_b in other_stocks:
        # é€å¯¹å¤„ç†

# âœ… æ”¹è¿›ï¼šæ‰¹é‡éšæœºé€‰æ‹©ï¼ˆä»å¯ä¼˜åŒ–ï¼‰
selected_stocks = np.random.choice(other_stocks, size=k, replace=False)

# âœ… æœ€ä¼˜ï¼šé¢„è®¡ç®—æ ‡ç­¾æ’åï¼Œåˆ†ä½æ•°åˆ†ç»„
label_ranks = np.argsort(np.argsort(label_values))  # ç™¾åˆ†ä½æ’å
# æŒ‰æ’ååŒºé—´åˆ†ç»„é‡‡æ ·
```

### 2.2 ğŸš€ **ç¼“å­˜å¸¸ç”¨è®¡ç®—**
**é—®é¢˜**ï¼šæ¯ä¸ªepochéƒ½é‡æ–°è®¡ç®—æ ‡ç­¾ã€åˆ†ä½æ•°
**è§£å†³**ï¼šç¼“å­˜æ—¥æœŸçº§åˆ«çš„è®¡ç®—ç»“æœ

```python
class DateCache:
    """æ—¥æœŸçº§åˆ«ç¼“å­˜"""
    def __init__(self):
        self.cache = {}
    
    def get_date_data(self, date, date_features, date_labels):
        if date not in self.cache:
            # è®¡ç®—å¹¶ç¼“å­˜
            self.cache[date] = {
                'valid_instruments': [...],
                'label_values': {...},
                'all_labels': np.array([...]),
                'feature_vectors': {...}
            }
        return self.cache[date]
```

### 2.3 ğŸš€ **å¹¶è¡Œæ—¥æœŸå¤„ç†**
**é—®é¢˜**ï¼šä¸²è¡Œå¤„ç†æ‰€æœ‰æ—¥æœŸ
**è§£å†³**ï¼šå¤šè¿›ç¨‹å¹¶è¡Œç”Ÿæˆé…å¯¹

```python
def process_date_parallel(date_data):
    """å•ä¸ªæ—¥æœŸçš„é…å¯¹ç”Ÿæˆï¼ˆæ— çŠ¶æ€ï¼‰"""
    date, date_features, date_labels, k, threshold = date_data
    # ... ç”Ÿæˆè¯¥æ—¥æœŸçš„é…å¯¹batch ...
    return batches

# å¤šè¿›ç¨‹å¹¶è¡Œ
with ProcessPoolExecutor(max_workers=n_workers) as executor:
    futures = [executor.submit(process_date_parallel, d) for d in all_dates]
```

### 2.4 ğŸš€ **LGBMå¿«é€Ÿè®­ç»ƒé…ç½®**
**é—®é¢˜**ï¼šé»˜è®¤å‚æ•°è®­ç»ƒæ…¢
**è§£å†³**ï¼šä¼˜åŒ–LGBMå‚æ•°

```python
self.params = {
    'objective': 'binary',
    'metric': 'auc',
    'boosting_type': 'gbdt',
    'num_leaves': 63,        # å‡å°‘ï¼š127 â†’ 63
    'learning_rate': 0.05,   # é™ä½ï¼š0.1 â†’ 0.05
    'feature_fraction': 0.6, # é™ä½ï¼š0.8 â†’ 0.6
    'bagging_fraction': 0.6, # é™ä½ï¼š0.8 â†’ 0.6
    'bagging_freq': 1,       # å¢åŠ é¢‘ç‡ï¼š5 â†’ 1
    'num_threads': n_workers, # å¹¶è¡Œçº¿ç¨‹
    'verbose': -1
}
```

### 2.5 ğŸš€ **PyTorchè®­ç»ƒåŠ é€Ÿ**
**é—®é¢˜**ï¼šå°batchã€æ— ä¼˜åŒ–
**è§£å†³**ï¼šæ··åˆç²¾åº¦ + æ›´å¤§batch

```python
# âœ… ä½¿ç”¨æ··åˆç²¾åº¦ï¼ˆå¦‚æœGPUæ”¯æŒï¼‰
scaler = torch.cuda.amp.GradScaler()

with torch.cuda.amp.autocast():
    pred = self.model(X_batch)
    loss = F.binary_cross_entropy(pred, y_batch)

scaler.scale(loss).backward()
scaler.step(self.optimizer)
scaler.update()

# âœ… å¢å¤§batch sizeï¼ˆå†…å­˜å…è®¸æ—¶ï¼‰
batch_size = 4096  # 1024 â†’ 4096
```

## ä¸‰ã€æ¶æ„ä¼˜åŒ–å»ºè®®

### 3.1 ğŸ—ï¸ **åˆ†å±‚é‡‡æ ·ç­–ç•¥**
```python
class HierarchicalPairSampler:
    """
    åˆ†å±‚é‡‡æ ·ï¼šå…ˆæŒ‰æ—¥æœŸï¼Œå†æŒ‰è‚¡ç¥¨ï¼Œé¿å…å…¨å±€O(nÂ²)
    """
    def __init__(self, n_bins=10):
        self.n_bins = n_bins
    
    def sample_pairs(self, date_data):
        # 1. æŒ‰æ”¶ç›Šç‡åˆ†æ¡¶
        bins = pd.qcut(label_values, self.n_bins, labels=False)
        
        # 2. åªåœ¨ä¸åŒæ¡¶ä¹‹é—´é‡‡æ ·
        for bin_a, bin_b in itertools.combinations(range(self.n_bins), 2):
            stocks_a = instruments[bins == bin_a]
            stocks_b = instruments[bins == bin_b]
            # é‡‡æ ·è·¨æ¡¶é…å¯¹
```

### 3.2 ğŸ—ï¸ **é”¦æ ‡èµ›å¹¶è¡ŒåŒ–**
```python
def run_parallel_tournaments(stocks, features, model, n_tournaments, n_workers):
    """å¹¶è¡Œè¿è¡Œå¤šä¸ªç‹¬ç«‹çš„é”¦æ ‡èµ›"""
    with ProcessPoolExecutor(max_workers=n_workers) as executor:
        futures = [
            executor.submit(run_single_tournament, stocks, features, model)
            for _ in range(n_tournaments)
        ]
        
    # èšåˆç»“æœ
    all_scores = defaultdict(list)
    for future in as_completed(futures):
        tournament_scores = future.result()
        for stock, score in tournament_scores.items():
            all_scores[stock].append(score)
```

## å››ã€é¢„æœŸæ•ˆæœ

| ä¼˜åŒ–é¡¹ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡å¹…åº¦ |
|--------|--------|--------|----------|
| **è®­ç»ƒå†…å­˜** | 7.3GB | **< 500MB** | **93% â†“** |
| **éªŒè¯å†…å­˜** | 1.6GB | **< 100MB** | **94% â†“** |
| **é…å¯¹ç”Ÿæˆ** | O(nÂ²) | O(n log n) | **80% â†“** |
| **è®­ç»ƒæ—¶é—´** | 30åˆ†é’Ÿ | **8åˆ†é’Ÿ** | **73% â†“** |
| **é¢„æµ‹æ—¶é—´** | 5åˆ†é’Ÿ | **2åˆ†é’Ÿ** | **60% â†“** |

## äº”ã€å®æ–½ä¼˜å…ˆçº§

### ğŸ”´ **P0 - å¿…é¡»ç«‹å³ä¿®å¤**
1. âœ… æµå¼æ•°æ®ç”Ÿæˆå™¨ï¼ˆè§£å†³OOMï¼‰
2. âœ… float32æ•°æ®ç±»å‹è½¬æ¢
3. âœ… éªŒè¯é›†å•batché‡‡æ ·

### ğŸŸ¡ **P1 - å¼ºçƒˆå»ºè®®**
1. â¬œ æ—¥æœŸçº§åˆ«ç¼“å­˜
2. â¬œ LGBMå‚æ•°ä¼˜åŒ–
3. â¬œ PyTorchæ··åˆç²¾åº¦

### ğŸŸ¢ **P2 - æ€§èƒ½ä¼˜åŒ–**
1. â¬œ åˆ†å±‚é‡‡æ ·ç­–ç•¥
2. â¬œ é”¦æ ‡èµ›å¹¶è¡ŒåŒ–
3. â¬œ å‘é‡åŒ–é…å¯¹é€‰æ‹©

## å…­ã€æœ€ç»ˆéªŒè¯ä»£ç 

```python
# å†…å­˜ç›‘æ§è£…é¥°å™¨
import psutil
import tracemalloc

def memory_profile(func):
    def wrapper(*args, **kwargs):
        tracemalloc.start()
        process = psutil.Process()
        mem_before = process.memory_info().rss / 1024 / 1024
        
        result = func(*args, **kwargs)
        
        mem_after = process.memory_info().rss / 1024 / 1024
        current, peak = tracemalloc.get_traced_memory()
        tracemalloc.stop()
        
        print(f"[Memory] {func.__name__}:")
        print(f"  RSS: {mem_before:.1f}MB â†’ {mem_after:.1f}MB")
        print(f"  Peak: {peak / 1024 / 1024:.1f}MB")
        return result
    return wrapper

# åº”ç”¨ç›‘æ§
@memory_profile
def _fit_pytorch_streaming(self, ...):
    # æµå¼è®­ç»ƒå®ç°
    pass
```

## æ€»ç»“

**æ ¸å¿ƒåŸåˆ™**ï¼š
1. **æ°¸ä¸**å…¨é‡åŠ è½½é…å¯¹æ•°æ®
2. **æ°¸è¿œ**ä½¿ç”¨float32
3. **å°½é‡**ç¼“å­˜é‡å¤è®¡ç®—
4. **å°½é‡**å¹¶è¡Œç‹¬ç«‹ä»»åŠ¡

æŒ‰ç…§ä»¥ä¸Šè¦ç‚¹ä¿®æ”¹åï¼Œä»£ç å¯ä»¥åœ¨**8GBå†…å­˜çš„æœºå™¨ä¸Šæµç•…è¿è¡Œ**ï¼Œè®­ç»ƒæ—¶é—´ä»**30åˆ†é’Ÿç¼©çŸ­è‡³5-8åˆ†é’Ÿ**ã€‚