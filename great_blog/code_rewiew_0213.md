# 针对alpha_mining/myportfolio.py的review：

1. 生成训练集中的股票配对时（PairwiseDataGenerator和StreamingPairwiseDataGenerator
），需要生成分位数差异大于给定阈值的股票对，但现在的复杂度达到了股票数量的三次方（遍历股票a、遍历股票b、计算a和b的分位数、最后从所有可能的股票b随机选择k个）。需要修改为线性复杂度：对每日的股票按label做排序，以股票总数为M，阈值为0.8为例，股票a只能选自index<0.2M的股票（否则不会存在收益率差距为0.8的股票b），假定股票a的分位数为0.15，那么直接从index>0.95M的股票中随机选择k个股票即可。
2. 在单淘汰赛和双败淘汰赛中，，返回的分数应当是获胜轮数，而不是现在的平均胜率。因为我们需要分数期望与真实排名单调，获胜轮数是单调的，后者不是。
3. 在混合排序方法中，使用随机匹配初始化+单淘汰赛的两阶段排序方法，可以有效避免强者提前相遇而爆冷出局，有效降低了排序的方差。然而现在的实现与这一思路相反，现在的实现是将粗排序的第一与第二匹配，这会让爆冷效应恶化而不是改善。正确的实现是按照粗排序的结果正确安排初始顺序，让第一名匹配N/2名，第二名匹配N/2+1名，并尽量在后续的比赛中也避免排名相近的对手提前相遇。
4. 在自适应排序方法中，使用了一种类似UCB的启发式方法来将排序资源集中在top-k边界附近，以最大化top-k选择的有效性。但实现存在错误：阶段二的轮数计算混淆了轮数与比较次数；使用完全在线的动态排序，每次只能推理一个样本，无法利用模型的批次推理加速，需要修改为每次取少量样本如5个样本批量推理；边界区域的candidate生成可能有大量重复；
5. 残差模型里处理奇数层的逻辑有问题，最后一层会被遗弃；
6. 使用重建特征作为辅助损失的模型里，需要对输入做随机mask后再做重建，否则只是一个trivial的压缩而不能学习到有意义的表征，正确做法是将输入随机mask，通过share encoder-decoder来计算重建损失，同时将原始输入（不mask）通过share encoder-classfication head做排序分类。推理时只使用第二条路径。
7. 移除代码中冗余的部分：合并PairwiseDataGenerator和StreamingPairwiseDataGenerator，通过参数开关控制是否流式；PairwiseRankModel._fit_pytorch已经弃用；PairwiseStrategy已经弃用；
8. 移除验证集只使用一个batch的功能，这会导致验证集评估不正确。实验中需要完整的验证集评估，修改为流式获取数据并累积计算。
9. 各个pytorch模型应当保持相同的推理接口和损失计算接口，提供各自的loss损失计算方法，而不需要在训练循环中使用大量if-else来计算推理结果和推理过程。
10. 绘制累积收益曲线图时，应当加入一条基准曲线-取大盘的累积变化。