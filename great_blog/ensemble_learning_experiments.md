# 集成学习实验计划

## 1. 背景与动机

### 1.1 当前实现的局限性

**当前实现**（`models.py`, `workflow.py`）：
- 每次只使用单一模型进行训练和预测
- 未利用模型差异性带来的性能提升
- 缺乏集成学习框架支持

**主要问题**：
1. **单一模型风险**：模型假设可能存在偏差，单一模型风险高
2. **未利用多样性**：不同模型架构（LGBM/MLP/Twin-Tower）有不同优势
3. **性能波动大**：单一模型在不同市场环境下表现不稳定
4. **置信度低**：没有多模型一致性验证，预测置信度低

### 1.2 集成学习优势

**核心思想**：通过组合多个模型的预测，提升整体性能

**理论依据**：
- **偏差-方差权衡**：集成可以降低单一模型的方差
- **多样性价值**：不同架构学习不同的特征表示
- **不确定性估计**：多模型预测差异提供不确定性估计
- **鲁棒性提升**：集成对异常值和过拟合更鲁棒

**预期效果**：
- **准确性提升**：年化收益提升2-7%
- **稳定性提升**：IC标准差降低15-30%，ICIR提升
- **置信度量化**：通过模型一致性量化预测置信度
- **风险管理**：不确定性高的时期降低仓位

---

## 2. 实验设计原则

### 2.1 固定条件

为避免混淆变量，以下参数在所有实验中保持固定：

- **特征**：使用现有200+因子（不做任何修改）
- **标签**：使用当前2日收益率标签（不做任何修改）
- **排序方法**：自适应边界聚焦（使用最优参数）
- **数据范围**：2017-2020年测试集
- **训练数据**：2008-2014年训练集，2015-2016年验证集
- **随机种子**：固定为42（确保可复现性）

### 2.2 评估标准

- **主要指标**：年化收益率（用于选择最优集成策略）
- **辅助指标**：IC、Rank IC、夏普比率、最大回撤、ICIR

### 2.3 基线模型准备

**阶段0：训练基线模型**（各类型，仅需一次）

```
基线模型列表：
1. LGBM基线
   - 训练参数：num_leaves=127, learning_rate=0.1
   - 保存路径：data/models/baseline_lgbm.pkl

2. MLP基线
   - 架构：[512, 256, 128]
   - 训练参数：epochs=20, dropout=0.3
   - 保存路径：data/models/baseline_mlp.pth

3. Twin-Tower基线
   - 架构：embedding_dim=64
   - 训练参数：epochs=20, dropout=0.3
   - 保存路径：data/models/baseline_twin_tower.pth

4. ResidualMLP基线
   - 架构：[512, 256, 128]
   - 训练参数：epochs=20, dropout=0.3
   - 保存路径：data/models/baseline_residual_mlp.pth
```

**后续实验**：加载预训练模型，仅测试集成策略

---

## 3. 实验列表

### 实验 0: 基线性能对比

**目标**：建立各基线模型的性能基准

**设置描述**：
- 模型类型：LGBM、MLP、Twin-Tower、ResidualMLP
- 评估方式：单独加载每个模型进行完整回测
- 对比维度：IC、年化收益、夏普比率、最大回撤、计算时间

**预期结果**（基于历史运行）：
```
LGBM:
  - IC: 0.035-0.045
  - 年化收益: 8-12%
  - 夏普比率: 0.9-1.1
  - 最大回撤: 30-35%
  - 训练时间: 2-3小时
  - 预测时间: 快速（分钟级）

MLP:
  - IC: 0.032-0.040
  - 年化收益: 7-10%
  - 夏普比率: 0.8-1.0
  - 最大回撤: 32-38%
  - 训练时间: 4-6小时
  - 预测时间: 中等

Twin-Tower:
  - IC: 0.030-0.038
  - 年化收益: 7-9%
  - 夏普比率: 0.8-0.9
  - 最大回撤: 33-40%
  - 训练时间: 5-7小时
  - 预测时间: 中等

ResidualMLP:
  - IC: 0.033-0.041
  - 年化收益: 7-11%
  - 夏普比率: 0.85-1.05
  - 最大回撤: 31-36%
  - 训练时间: 5-8小时
  - 预测时间: 中等
```

**对比结论**：
- LGBM通常最快且性能最好
- 深度学习模型性能接近，但训练更慢
- 不同模型在不同市场环境下可能有相对优势

---

### 实验 1: 简单平均集成

**目标**：测试最简单的集成策略

**变量**：平均方式

**详细配置对比**：

**配置1: 算术平均**
- 方法：对所有模型的预测分数求和后除以模型数量
- 公式：ensemble_score = (score_lgbm + score_mlp + score_twin + score_resid) / 4
- 权重：均等权重 [0.25, 0.25, 0.25, 0.25]
- 特点：最简单，假设所有模型同等重要
- 预期效果：比平均单一模型性能提升1-3%
- 优势：实现简单，无过拟合风险
- 劣势：未考虑模型性能差异

**配置2: 几何平均**
- 方法：对分数先指数变换再平均
- 公式：ensemble_score = exp(average(log(scores)))
- 权重：隐式均等
- 特点：对异常值更鲁棒
- 预期效果：与算术平均类似，但更稳定
- 优势：减少极端分数影响
- 劣势：计算复杂度略高

**配置3: 中位数集成**
- 方法：取所有模型预测的中位数
- 公式：ensemble_score = median([score_lgbm, score_mlp, score_twin, score_resid])
- 特点：对异常模型预测鲁棒
- 预期效果：略优于算术平均（稳定性+0.5-1%）
- 优势：单个模型错误预测影响小
- 劣势：未充分利用好模型的优势

**配置4: 截尾平均**
- 方法：去掉最高和最低预测后平均
- 步骤：
  1. 排序4个模型预测
  2. 去掉最高和最低
  3. 对中间2个求平均
- 特点：减少极端预测影响
- 预期效果：与中位数类似
- 优势：简单直观
- 劣势：浪费了2个模型的预测

**关键假设**：
- 简单平均能带来稳定性提升
- 不同模型有互补的预测优势
- 异常预测会被其他模型"纠正"

**评估方法**：
- 对比各集成方式的年化收益率
- 对比IC标准差（稳定性）
- 分析预测一致性（模型间相关系数）

---

### 实验 2: 验证集加权集成

**目标**：基于验证集性能动态分配权重

**变量**：权重计算方式

**详细配置对比**：

**配置1: 验证集IC加权**
- 权重计算步骤：
  1. 在验证集（2015-2016）上计算各模型IC
  2. 归一化：weight_i = IC_i / sum(ICs)
  3. 应用到测试集：ensemble = sum(weight_i × score_i)
- 示例：
  - IC_lgbm = 0.040, IC_mlp = 0.035, IC_twin = 0.033, IC_resid = 0.036
  - weights = [0.29, 0.25, 0.24, 0.26]
- 特点：基于客观性能指标加权
- 预期效果：比等权平均提升1-2%
- 优势：理论上最优（如果验证集代表测试集）
- 劣势：验证集过拟合风险

**配置2: 验证集年化收益加权**
- 权重计算步骤：
  1. 在验证集上回测各模型
  2. 提取年化收益率
  3. 归一化：weight_i = return_i / sum(returns)
- 示例：
  - return_lgbm = 10%, return_mlp = 8%, return_twin = 7%, return_resid = 9%
  - weights = [0.29, 0.24, 0.21, 0.26]
- 特点：基于实际投资目标加权
- 预期效果：与IC加权类似，可能略优（年化收益+0.5-1%）
- 优势：直接优化投资目标
- 劣势：验证集表现可能不外推

**配置3: 验证集夏普比率加权**
- 权重计算步骤：
  1. 在验证集上计算各模型夏普比率
  2. 归一化：weight_i = sharpe_i / sum(sharpes)
- 示例：
  - sharpe_lgbm = 1.05, sharpe_mlp = 0.95, sharpe_twin = 0.90, sharpe_resid = 1.00
  - weights = [0.27, 0.25, 0.23, 0.26]
- 特点：风险调整收益加权
- 预期效果：稳定性最优（ICIR提升5-10%）
- 优势：考虑风险因素
- 劣势：权重差异较小

**配置4: 滚动窗口IC加权**
- 权重计算步骤：
  1. 计算验证集每月IC
  2. 使用最近3个月平均IC
  3. 归一化权重
- 特点：动态调整，适应模型性能变化
- 预期效果：可能略优于静态IC加权（+0.2-0.5%）
- 优势：更适应市场环境变化
- 劣势：增加计算复杂度

**配置5: 排序加权**
- 权重计算步骤：
  1. 验证集上各模型IC排序
  2. 使用排序位次作为权重（非线性变换）
  3. 示例：1st→0.4, 2nd→0.3, 3rd→0.2, 4th→0.1
- 特点：强调好模型，非线性权重分配
- 预期效果：可能优于线性加权（+0.3-0.8%）
- 优势：充分用好模型优势
- 劣势：差模型权重可能过小

**关键假设**：
- 验证集性能与测试集性能正相关
- 加权集成优于等权集成
- 权重稳定性随时间变化不大

**评估方法**：
- 对比各加权方式的年化收益率
- 分析权重稳定性（不同时间段权重变化）
- 对比加权vs等权的改进幅度

---

### 实验 3: 排序集成

**目标**：对预测排序后集成，而非直接集成分数

**变量**：排序集成方式

**详细配置对比**：

**配置1: 平均分数后排序**
- 步骤：
  1. 加权平均各模型预测分数（使用实验2最优加权）
  2. 对集成分数排序得到最终股票排序
  3. 选择Top-K股票
- 特点：在分数空间集成
- 预期效果：作为对比基准
- 优势：直观简单
- 劣势：分数尺度可能不一致

**配置2: 平均排序后投票**
- 步骤：
  1. 各模型独立预测并排序（1-N）
  2. 对每只股票的排序位次求平均
  3. 按平均排序位次重新排序
  4. 选择Top-K股票
- 示例：
  - 股票A在各模型排序：[5, 8, 3, 6]
  - 平均排序：(5+8+3+6)/4 = 5.5
- 特点：在排序空间集成
- 预期效果：可能优于分数集成（+0.5-1.5%）
- 优势：对分数尺度差异不敏感
- 劣势：丢失分数强度信息

**配置3: Borda计数法**
- 步骤：
  1. 每个模型的排序：N只股票 → 1-N排名
  2. 每只股票的Borda分数 = Σ(N - rank_in_model_i)
  3. 按Borda分数排序
  4. 选择Top-K股票
- 示例（N=300）：
  - 股票A各模型排名：[5, 8, 3, 6]
  - Borda分数 = (300-5) + (300-8) + (300-3) + (300-6) = 1178
- 特点：经典投票方法，重视好排名
- 预期效果：优于简单平均排序（+0.2-0.5%）
- 优势：理论上更合理
- 劣势：计算稍复杂

**配置4: Copeland规则**
- 步骤：
  1. 对每只股票，计算 pairwise 对决
  2. 胜者得1分，败者得0分
  3. 按总分排序
  4. 选择Top-K股票
- 特点：考虑相对优势
- 预期效果：与Borda类似
- 优势：考虑所有两两比较
- 劣势：计算量大（O(N²)）

**配置5: 位置加权投票**
- 步骤：
  1. 每个模型的排序：1-N排名
  2. 权重随名次递减：weight = 1 / log(rank + 1)
  3. 加权平均排序位次
  4. 按加权位次排序
- 示例：
  - 排名1权重：1/log(2) ≈ 1.44
  - 排名50权重：1/log(51) ≈ 0.26
  - 排名100权重：1/log(101) ≈ 0.19
- 特点：重视好排名，平滑递减
- 预期效果：可能优于Borda（+0.3-0.7%）
- 优势：更灵活的权重分配
- 劣势：权重函数需要调优

**配置6: Top-K交集**
- 步骤：
  1. 各模型独立选择Top-K股票（如K=30）
  2. 取交集（所有模型都选中的股票）
  3. 如交集不足，取并集补足
- 特点：高置信度选股（所有模型一致）
- 预期效果：稳定性显著提升（ICIR+15-25%），但收益可能略降（-1-3%）
- 优势：最保守，最稳定
- 劣势：可能错失机会

**关键假设**：
- 排序空间集成比分数空间集成更稳定
- 投票方法优于简单平均
- 位置加权能充分利用好排名信息

**评估方法**：
- 对比各排序集成方式的Top-K准确率
- 对比年化收益率和夏普比率
- 分析交集稳定性（交集大小变化）

---

### 实验 4: Stacking集成

**目标**：训练元学习器（meta-learner）组合基座模型

**变量**：元学习器架构

**详细配置对比**：

**配置1: 线性回归Stacking**
- 元特征：各基座模型的预测分数
  - feature = [score_lgbm, score_mlp, score_twin, score_resid]
- 元标签：真实2日收益率
- 元模型：Linear Regression
- 训练集：验证集（2015-2016）
- 测试集：测试集（2017-2020）
- 正则化：Ridge (L2 penalty, α=1.0)
- 特点：最简单的元学习器
- 预期效果：优于简单加权（+1-2%）
- 优势：可解释性强（权重系数）
- 劣势：仅线性组合

**配置2: 岭回归Stacking**
- 元特征：各基座模型的预测分数
- 元标签：真实2日收益率
- 元模型：Ridge Regression (L2 penalty)
- 超参数搜索：α ∈ {0.01, 0.1, 1.0, 10.0}
- 验证集：训练集的10%作为验证
- 特点：防止过拟合
- 预期效果：可能优于线性回归（+0.2-0.5%）
- 优势：更鲁棒
- 劣势：需要调参

**配置3: 轻量级MLP Stacking**
- 元特征：各基座模型的预测分数
- 元标签：真实2日收益率
- 元模型：MLP (架构 [16, 8])
- 激活：ReLU
- 正则化：Dropout=0.3, L2 weight decay=1e-4
- 训练轮次：50 epochs
- 早停：patience=10
- 特点：学习非线性组合
- 预期效果：优于线性模型（+0.5-1.5%）
- 优势：更强表达能力
- 劣势：有轻微过拟合风险

**配置4: 梯度提升MLP Stacking**
- 元特征：各基座模型的预测分数
- 元标签：真实2日收益率
- 元模型：ResidualMLP (架构 [32, 16, 8])
- 激活：ReLU
- 正则化：Dropout=0.3, LayerNorm
- 训练轮次：50 epochs
- 早停：patience=10
- 特点：更强的非线性能力
- 预期效果：可能优于轻量级MLP（+0.2-0.5%）
- 优势：更深网络，更强能力
- 劣势：过拟合风险更高

**配置5: XGBoost Stacking**
- 元特征：各基座模型的预测分数
- 元标签：真实2日收益率
- 元模型：XGBoost Regressor
- 超参数：
  - max_depth: 3
  - learning_rate: 0.05
  - n_estimators: 100
  - subsample: 0.8
  - colsample_bytree: 0.8
- 特点：树模型集成
- 预期效果：与MLP Stacking类似（+0.8-1.8%）
- 优势：训练快，不易过拟合
- 劣势：非线性能力不如神经网络

**配置6: 时序Stacking**
- 元特征：
  - 历史预测分数（各模型过去1期）
  - 当前预测分数（各模型当前期）
- 元标签：真实2日收益率
- 元模型：Ridge Regression
- 特点：利用时序信息
- 预期效果：可能优于静态Stacking（+0.3-0.7%）
- 优势：捕捉动态模式
- 劣势：需要历史数据，实现复杂

**关键假设**：
- 元学习器能学到最优组合方式
- 元特征（基座预测）包含有用信息
- 验证集训练的元学习器能泛化到测试集

**评估方法**：
- 对比各元学习器的年化收益率
- 分析元学习器权重系数（可解释性）
- 对比训练集vs测试集性能（过拟合检测）

---

### 实验 5: 自适应集成

**目标**：根据预测置信度动态调整集成策略

**变量**：置信度估计与自适应策略

**详细配置对比**：

**配置1: 预测不确定性加权**
- 置信度估计：standard deviation of predictions
  - uncertainty = std([score_lgbm, score_mlp, score_twin, score_resid])
- 权重调整：weight_i = 1 / (1 + uncertainty)
- 逻辑：模型预测差异大时（不确定性高），降低该股票权重
- 应用方式：最终分数 = 原始分数 × confidence_weight
- 特点：不确定性高的时期降低仓位
- 预期效果：最大回撤降低（5-10%），年化收益略降（-1-2%）
- 优势：风险管理
- 劣势：可能过于保守

**配置2: 预测一致性筛选**
- 置信度估计：模型预测一致性
  - consensus = 1 - std(normalized_scores)
- 筛选策略：仅保留一致性>阈值的股票
- 阈值扫描：threshold ∈ {0.5, 0.6, 0.7, 0.8, 0.9}
- 选股数量：从Top100中筛选
- 特点：仅交易高置信度股票
- 预期效果：夏普比率提升（+10-15%），年化收益略降（-2-4%）
- 优势：高稳定性
- 劣势：错失机会

**配置3: 动态权重调整**
- 权重计算方式：滚动窗口验证集IC
  - 使用最近3个月验证集IC
  - 每月更新权重
- 示例时间线：
  - Month 1: IC_lgbm=0.04, IC_mlp=0.03 → weights=[0.57, 0.43]
  - Month 2: IC_lgbm=0.035, IC_mlp=0.036 → weights=[0.49, 0.51]
  - Month 3: IC_lgbm=0.038, IC_mlp=0.034 → weights=[0.53, 0.47]
- 特点：适应模型性能变化
- 预期效果：比静态加权略优（+0.3-0.6%）
- 优势：更适应市场环境
- 劣势：计算复杂度增加

**配置4: 市场环境自适应集成**
- 环境识别：基于市场波动率
  - 低波动（年化<15%）：使用等权集成
  - 高波动（年化>25%）：使用验证集IC加权
  - 中等波动：使用排序集成
- 特点：根据市场状态选择最优集成策略
- 预期效果：不同环境下均保持稳定（ICIR+10-15%）
- 优势：自适应
- 劣势：增加系统复杂度

**配置5: 模型数量自适应**
- 基线：始终使用所有4个模型
- 自适应策略：
  - 高不确定性：仅使用验证集IC>0.035的模型
  - 中等不确定性：使用所有模型
- 示例：
  - 高不确定性月：仅使用LGBM和ResidualMLP
  - 正常月：使用全部4个模型
- 特点：在不确定性高时简化集成
- 预期效果：计算效率提升，性能持平
- 优势：节省资源
- 劣势：可能损失多样性

**配置6: 集成规模搜索**
- 目标：找到最优基座模型组合
- 搜索策略：
  - 所有2模型组合（C(4,2)=6种）
  - 所有3模型组合（C(4,3)=4种）
  - 所有4模型组合（1种）
- 对比指标：验证集年化收益率
- 选择标准：最高验证集年化收益
- 特点：找到最优子集
- 预期效果：可能减少冗余模型（+0.2-0.8% vs 全部4个）
- 优势：降低复杂度
- 劣势：损失多样性

**关键假设**：
- 预测不确定性可量化
- 不确定性与预测误差正相关
- 自适应策略能应对环境变化

**评估方法**：
- 对比各自适应策略在不同市场环境下的表现
- 分析置信度与预测准确性的相关性
- 对比静态vs动态集成的改进幅度

---

### 实验 6: 模型差异性优化

**目标**：最大化基座模型间的多样性，提升集成效果

**变量**：差异性来源

**详细配置对比**：

**配置1: 不同的训练数据划分**
- 划分策略：
  - 模型1: 2008-2014完整训练集
  - 模型2: 2008-2012训练集
  - 模型3: 2013-2014训练集
- 特点：不同时间段数据学习不同模式
- 预期效果：模型差异性提升，集成效果提升（+0.5-1%）
- 优势：自然多样性
- 劣势：部分模型训练数据少

**配置2: 不同的特征子集**
- 特征分组：
  - 组1：价格相关特征（100个）
  - 组2：成交量相关特征（50个）
  - 组3：技术指标（50个）
  - 组4：全部特征（200个）
- 分配策略：
  - LGBM: 全部特征
  - MLP: 价格+成交量特征
  - Twin-Tower: 技术指标特征
  - ResidualMLP: 全部特征
- 特点：不同模型关注不同信息源
- 预期效果：特征互补性，集成提升（+0.7-1.5%）
- 优势：视角多样
- 劣势：可能损失重要特征

**配置3: 不同的随机种子**
- 设置：
  - 所有模型使用相同架构和数据
  - 仅随机种子不同（42, 123, 456, 789）
- 特点：仅从随机性产生多样性
- 预期效果：集成效果提升有限（+0.2-0.5%）
- 优势：实现简单
- 劣势：多样性来源单一

**配置4: 不同的超参数**
- LGBM超参：
  - 模型1: num_leaves=127, learning_rate=0.1
  - 模型2: num_leaves=63, learning_rate=0.05
- MLP超参：
  - 模型1: hidden=[512,256,128], dropout=0.3
  - 模型2: hidden=[256,128], dropout=0.5
- 特点：不同复杂度和正则化强度
- 预期效果：集成效果提升（+0.5-1%）
- 优势：不同偏好的模型
- 劣势：调参复杂度增加

**配置5: 不同的架构族**
- 架构分配：
  - 树模型族：LGBM
  - 神经网络族：MLP, ResidualMLP, Twin-Tower
- 特点：不同算法原理
- 预期效果：最大多样性，集成提升最大（+1-2%）
- 优势：差异性最显著
- 劣势：实现复杂度最高

**配置6: Bootstrap采样**
- 方法：
  - 每个模型使用Bootstrap采样训练集
  - 采样比例：80%
  - 采样次数：4个模型，各采样一次
- 特点：不同样本产生多样性
- 预期效果：集成效果提升（+0.8-1.2%）
- 优势：理论成熟
- 劣势：训练数据少

**关键假设**：
- 模型间负相关或低相关最优
- 差异性越大，集成收益越大（边际收益递减）
- 多样性来源组合优于单一来源

**评估方法**：
- 计算模型间预测相关系数矩阵
- 对比各差异性配置的集成收益
- 分析相关性vs集成效果关系

---

## 4. 实验执行与评估流程

### 4.1 执行顺序

```
实验0（基线性能对比）
    ↓ 确定各基线模型性能
    ↓
实验1（简单平均）→ 确定最优简单集成方式
    ↓
实验2（验证集加权）→ 确定最优加权方式
    ↓
实验3（排序集成）→ 与加权方式对比
    ↓
实验4（Stacking）→ 训练元学习器
    ↓
实验5（自适应集成）→ 评估动态策略
    ↓
实验6（差异性优化）→ 找到最优多样性配置
    ↓
综合分析与最优配置推荐
```

### 4.2 结果记录

每个实验需要记录以下指标：

**集成性能指标**：
- IC, Rank IC, ICIR
- 年化收益率, 夏普比率, 最大回撤, Calmar比率
- 换手率

**多样性指标**：
- 模型间预测相关系数矩阵
- 平均相关系数
- 最低相关系数

**效率指标**：
- 总训练时间
- 预测时间（毫秒/股票）
- 内存占用

**相对提升**：
- 相对最佳基线模型的提升百分比
- 相对简单平均集成的提升百分比

**结果存储路径**：
```
data/experiments/ensemble_learning/
├── exp00_baseline/
│   ├── config.json
│   ├── results.csv
│   └── plots/
├── exp01_simple_average/
├── exp02_validation_weighted/
├── exp03_rank_ensemble/
├── exp04_stacking/
├── exp05_adaptive/
└── exp06_diversity/
```

### 4.3 可视化分析

**关键可视化**：

1. **基线对比图**
   - 各基线模型性能对比（柱状图）
   - IC、年化收益、夏普比率、最大回撤

2. **集成方式对比图**
   - 不同集成方式性能对比（柱状图）
   - 简单平均 vs 加权平均 vs 排序集成 vs Stacking

3. **权重分析图**
   - 验证集IC权重系数（柱状图）
   - 权重随时间变化（折线图）

4. **相关性矩阵热力图**
   - 模型间预测相关系数矩阵
   - 不同差异性配置的相关性对比

5. **置信度分析图**
   - 不确定性 vs 预测误差散点图
   - 一致性 vs 预测准确率散点图

---

## 5. 预期贡献

### 5.1 性能提升预期

基于集成学习理论，预期达到以下效果：

**最坏情况**（简单平均）：
- IC提升：+0.002-0.005（从~0.035到~0.037-0.040）
- 年化收益提升：+1-3%（从~9%到~10-12%）
- 夏普比率提升：+0.05-0.15（从~0.95到~1.00-1.10）

**中等情况**（加权/排序集成）：
- IC提升：+0.005-0.010（从~0.035到~0.040-0.045）
- 年化收益提升：+2-5%（从~9%到~11-14%）
- 夏普比率提升：+0.10-0.25（从~0.95到~1.05-1.20）

**最好情况**（Stacking + 差异性优化）：
- IC提升：+0.010-0.020（从~0.035到~0.045-0.055）
- 年化收益提升：+4-7%（从~9%到~13-16%）
- 夏普比率提升：+0.20-0.40（从~0.95到~1.15-1.35）
- ICIR提升：+20-30%（从~2.5到~3.0-3.25）

**稳定性提升**：
- IC标准差降低：15-30%
- 月度胜率提升：+5-10个百分点

### 5.2 学术贡献

- **实证研究**：集成学习在pairwise排序量化投资中的系统性应用
- **方法对比**：多种集成策略的全面对比分析
- **设计原则**：为量化投资中的集成学习提供实践指导

### 5.3 实践贡献

- **性能提升**：可操作的4-7%年化收益提升
- **框架实现**：完整的集成学习框架，可复用于其他策略
- **风险管理**：通过不确定性量化提升风险管理

---

## 6. 时间估算

| 实验编号 | 实验名称 | 配置数量 | 预计耗时（小时） |
|---------|---------|---------|----------------|
| 0 | 基线性能对比 | 4个模型 | 8-12 |
| 1 | 简单平均集成 | 4种方式 | 6-10 |
| 2 | 验证集加权集成 | 5种加权方式 | 8-12 |
| 3 | 排序集成 | 6种排序方式 | 8-12 |
| 4 | Stacking集成 | 6种元学习器 | 10-15 |
| 5 | 自适应集成 | 6种自适应策略 | 10-15 |
| 6 | 模型差异性优化 | 6种差异性来源 | 12-18 |
| **总计** | | | **62-94 小时** |

**建议执行周期**：2-3周（每周20-30小时计算时间）

---

## 7. 风险与缓解

### 7.1 技术风险

| 风险 | 影响 | 缓解措施 |
|-----|------|---------|
| 验证集过拟合 | 元学习器在验证集上好但测试集差 | 时序交叉验证，正则化 |
| 模型冗余 | 某些模型没有贡献 | 差异性分析，模型选择 |
| 计算资源需求大 | 训练和预测时间增加 | 模型并行化，批处理优化 |

### 7.2 业务风险

| 风险 | 影响 | 缓解措施 |
|-----|------|---------|
| 系统复杂度增加 | 维护困难 | 模块化设计，完整文档 |
| 实盘性能差于回测 | 集成优势消失 | 模拟盘验证，渐进部署 |

---

## 8. 成功标准

**实验计划成功的标志**：
1. ✓ 找到相对于最佳基线模型有显著提升（年化收益 > 2%）的集成策略
2. ✓ 理解不同集成策略对性能的影响规律
3. ✓ 形成可复现的集成学习框架
4. ✓ 完成实验报告与可视化分析
5. ✓ 提供明确的集成配置推荐
